# --------------------------------------------------------------------------------------------#
#                                  STABLE DIFFUSION EXTENSION                                 #
# This file contains the documentation and debug settings for the Stable Diffusion extension. #
# --------------------------------------------------------------------------------------------#

dark_theme: true
show_controls: true
mode: chat
chat_style: cai-chat
character: Assistant
preset: Debug-deterministic
seed: 1337
stream: true

default_extensions:
  - gallery
  - stable_diffusion

#----------------------#
# API ENDPOINT DETAILS #
#----------------------#

## Sets the API endpoint to use for generating images.
## If you are using the default stable-diffusion-webui settings, you do not need to change this.
stable_diffusion-api_endpoint: "http://127.0.0.1:7860/sdapi/v1"

## Leave as-is if you did not set up any authentication for the API.
stable_diffusion-api_username: ""
stable_diffusion-api_password: ""

#-----------------------------#
# IMAGE GENERATION PARAMETERS #
#-----------------------------#

stable_diffusion-base_prompt: "RAW photo, subject, 8k uhd, dslr, soft lighting, high quality, film grain, Fujifilm XT3"
stable_diffusion-base_negative_prompt: "(deformed iris, deformed pupils, semi-realistic, cgi, 3d, render, sketch, cartoon, drawing, anime), text, cropped, out of frame, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, long neck"
stable_diffusion-sampler_name: "DPM SDE"
stable_diffusion-sampling_steps: 25
stable_diffusion-width: 512
stable_diffusion-height: 512
stable_diffusion-cfg_scale: 6
stable_diffusion-clip_skip: 1
stable_diffusion-seed: -1

#------------------#
# USER PREFERENCES #
#------------------#

## Sets if debug mode (e.g. for additional logs) should be enabled
stable_diffusion-debug_mode_enabled: true

## Sets if generated images should be saved to the "outputs" folder inside the stable_diffusion extension directory.
stable_diffusion-save_images: true

## Defines how image generation should be triggered. Possible values:
##  - "continuous": Always generate images.
##  - "interactive": Generate images only if a message with a triggering text was sent.
##  - "manual": Generates images only if the image generation button was pressed. (WIP, not implemented yet)
stable_diffusion-trigger_mode: "interactive"

## Set's how the prompt for image generation should be generated. Possible values:
##  - "static": Uses the prompt option as-is ignoring any chat context.
##  - "generated_text": Uses the generated output as-is as prompt.
##  - "dynamic": Generates a dynamic prompt using the subject_regex, default_subject and description_prompt options.
## The result is combined with the base_prompt and base_negative_prompt options.
stable_diffusion-interactive_mode_prompt_generation_mode: "dynamic"

## Defines the regex pattern for the input message which triggers image generation in interactive mode.
stable_diffusion-interactive_mode_input_trigger_regex: >-
  .*(draw|paint|create|send|upload|add|show|attach|generate)\b.+?\b(image|pic(ture)?|photo|snap(shot)?|selfie|meme)(s?)

## Defines the regex pattern for the generated output message which triggers image generation in interactive mode.
stable_diffusion-interactive_mode_output_trigger_regex: >-
  .*[*([]?(draws|paints|creates|sends|uploads|adds|shows|attaches|generates|here (is|are))\b.+?\b(image|pic(ture)?|photo|snap(shot)?|selfie|meme)(s?)

## Defines the regex pattern for extracting the subject of the message for dynamic prompt generation in interactive mode.
## Only used when prompt_generation_mode is set to "dynamic".
stable_diffusion-interactive_mode_subject_regex: >-
  .*\b(of)\b(.+?)(?:[.!?]|$)

## Sets the default subject to use instead if no subject was found in the input message using the subject_regex option.
## Only used when prompt_generation_mode is set to "dynamic".
stable_diffusion-interactive_mode_default_subject: "your appearance, your surroundings and what you are doing right now"

## The text to use for generating a stable diffusion compatible description of the given subject. Replaces the original input message.
## Only used when prompt_generation_mode is set to "dynamic".
stable_diffusion-interactive_mode_description_prompt: >
  You are now a text generator for the Stable Diffusion AI image generator. You will generate a text prompt for it.

  Describe [subject] using comma-separated tags only. Do not use sentences.
  Include many tags such as tags for the environment, gender, clothes, age, location, light, daytime, angle, pose, etc.

  Very important: only write the comma-separated tags. Do not write anything else. Do not ask any questions. Do not talk.

## Set's how the base prompt for image generation should be generated. Possible values:
##  - "static": Uses the prompt option as-is ignoring any chat context.
##  - "generated_text": Uses the generated output as-is as prompt.
## The result is combined with the base_prompt and base_negative_prompt options.
stable_diffusion-continuous_mode_prompt_generation_mode: "generated_text"

## If enabled, will automatically unload the LLM model from VRAM and then load the SD model instead when generating images.
## After the image is generated, it will unload the SD model again and then reload the LLM model.
## Saves VRAM but will slow down generation speed. Only recommended if you have a low amount of VRAM or use very large models.
stable_diffusion-dynamic_vram_reallocation_enabled: false

## Do not stream messages if generating images at the same time. Improves generation speed.
stable_diffusion-dont_stream_when_generating_images: true

## Defines regex based rules that triggers the given actions.
## regex: The regex pattern that triggers the action (optional)
## negative_regex: Do not trigger the action if the text matches this regex (optional)
## match: A list of where to match the regex. Available options:
## - "input": match on input text.
## - "input_sentence": match on any sentence in input text.
## - "output": match on generated output text.
## - "output_sentence": match on any sentence in generated output text.
## - "character_name": match on current character name (only if using gallery extension).
## actions: A list of actions to perform if the regex matches.
## - name: The name of the action to perform.
##   Available options:
##   - "prompt_append": appends the given text in "args" to the image generation prompt if an image is to be generated.
##   - "negative_prompt_append": appends the given text in "args" to the image generation negative prompt if an image is to be generated.
##   - "skip_generation": force skips any image generation.
##   - "faceswaplab_enable": force enables face swap with FaceSwapLab.
##   - "faceswaplab_disable": force disables face swap with FaceSwapLab.
##   - "faceswaplab_set_source_face": sets source face for FaceSwapLab (requires "args" to be set to a valid source face).
##   - "reactor_enable": force enables face swap with ReActor.
##   - "reactor_disable": force disables face swap with ReActor.
##   - "reactor_set_source_face": sets source face for ReActor (requires "args" to be set to a valid source face).
## - args: The arguments to pass to the action (optional).
stable_diffusion-generation_rules:
  # Add details to the prompt if the input text or output text contains the word "detailed".
  - regex: .*\b(detailed)\b
    match: ["input", "output"]
    actions:
      - name: "prompt_append"
        args: "(high resolution, detailed, realistic, vivid: 1.2), hdr, 8k, <lora:add_details:1>"

  # Append a prompt and negative prompt describing the characters look if the character's name equals "Assistant".
  - regex: ^Assistant$
    match: ["character_name"]
    actions:
      - name: "prompt_append"
        args: "small cute robot, monochrome, droid, 3d render, white reflective plastic body, simple, 3DMM, <lora:3DMM_V12:1>"
      - name: "negative_prompt_append"
        args: "humanoid, human, person, animal, anthropomorphic"

  # Enable face swap via FaceSwapLab (see below for documentation) if the character's name equals "Example".
  - regex: ^Example$
    match: ["character_name"]
    actions:
      - name: "faceswaplab_enable"
      - name: "faceswaplab_set_source_face"
        args: "file:///{STABLE_DIFFUSION_EXTENSION_DIRECTORY}/assets/example_face.jpg"

#-----------------#
# POST PROCESSING #
#-----------------#

## Sets if generated images should be upscaled.
stable_diffusion-upscaling_enabled: false

## Sets the upscaler to use for upscaling generated images.
## Some examples are: Latent, LDSR, RealESRGAN 4x+, Lanczos, Nearest, etc.
stable_diffusion-upscaling_upscaler: "RealESRGAN 4x+"

## Amount to upscale by (1 = 100%, 2 = 200%, etc.).
stable_diffusion-upscaling_scale: 2

## Sets if HiRes.fix should be enabled.
stable_diffusion-hires_fix_enabled: false

## Sets the sampler to use for HiRes.fix.
stable_diffusion-hires_fix_sampler: "UniPC"

## Sets the amount of steps for HiRes.fix.
stable_diffusion-hires_sampling_steps: 10

## Sets the denoising strength for HiRes.fix.
stable_diffusion-hires_fix_denoising_strength: 0.2

## Sets if faces should be enhanced (or "restored") in generated images.
stable_diffusion-restore_faces_enabled: false

#-------------#
# FACESWAPLAB #
#-------------#

## Apply face swapping using FaceSwapLab.
## Requires the sd-webui-faceswaplab extension to be installed.
## Repository: https://github.com/glucauze/sd-webui-faceswaplab

## Sets if faces should be swapped in generated images.
stable_diffusion-faceswaplab_enabled: false

## Sets the source image with the face to use for face swapping.
## It's possible to set it in 3 ways:
##   1. Local file: "file:///./example.jpg"
##   2. URL: "https://some-site.com/example.png"
##   3. (recommended) FaceSwapLab face checkpoint: "checkpoint://example"
##      You can see the list of available checkpoints in the "models/faceswaplab/faces" directory inside your Stable Diffusion WebUI directory.
##      See https://github.com/glucauze/sd-webui-faceswaplab#build-and-use-checkpoints- for more on how to create face checkpoints.
stable_diffusion-faceswaplab_source_face: "file:///{STABLE_DIFFUSION_EXTENSION_DIRECTORY}/assets/example_face.jpg"

## Only swap faces if same gender.
stable_diffusion-faceswaplab_same_gender_only: true

## If enabled, order source faces by size.
## Otherwise, order source faces from left to right.
stable_diffusion-faceswaplab_sort_by_size: true

## Use the nth face in the source face image as reference face
## Note: the first face is 0, the second face is 1, etc.
##
## Example:
## If you have 3 faces in the source image and set this to 1, it will use the second face from left to right if sort_by_size is set to false.
## If sort_by_size is true, it will use the second largest face instead.
stable_diffusion-faceswaplab_source_face_index: 0

## Use the nth face in the generated image as the face to swap out
## See source_face_index for more info
stable_diffusion-faceswaplab_target_face_index: 0

## Sets if the face should be upscaled
stable_diffusion-faceswaplab_upscaling_enabled: false

## Sets the upscaler to use for upscaling faces
## Some examples are: Latent, LDSR, RealESRGAN 4x+, Lanczos, Nearest, etc.
stable_diffusion-faceswaplab_upscaling_upscaler: "RealESRGAN 4x+"

## Amount to upscale the face by (1 = 100%, 2 = 200%, etc.)
stable_diffusion-faceswaplab_upscaling_scale: 2

## Visibility of the upscaled face (0.0 - 1.0)
stable_diffusion-faceswaplab_upscaling_visibility: 1

## Sets if the final result should be upscaled
stable_diffusion-faceswaplab_postprocessing_upscaling_enabled: false

## Sets the upscaler to use for upscaling final result image after swapping
## Some examples are: Latent, LDSR, RealESRGAN 4x+, Lanczos, Nearest, etc.
stable_diffusion-faceswaplab_postprocessing_upscaling_upscaler: "RealESRGAN 4x+"

## Amount to upscale the final result by (1 = 100%, 2 = 200%, etc.)
stable_diffusion-faceswaplab_postprocessing_upscaling_scale: 2

## Visibility of the final result upscale (0.0 - 1.0)
stable_diffusion-faceswaplab_postprocessing_upscaling_visibility: 1

## Sets if the face should be enhanced (or "restored") during swapping
stable_diffusion-faceswaplab_restore_face_enabled: false

## Model to use for enhancing the face (CodeFormer, GFPGAN)
stable_diffusion-faceswaplab_restore_face_model: "CodeFormer"

## Visibility of the restored face (0.0 - 1.0)
stable_diffusion-faceswaplab_restore_face_visibility: 1

## Weight of the CodeFormer model (0.0 - 1.0)
stable_diffusion-faceswaplab_restore_face_codeformer_weight: 1

## Sets if the faces should be enhanced (or "restored") in the final result image after swapping
stable_diffusion-faceswaplab_postprocessing_restore_face_enabled: false

## Model to use for restoring the faces (CodeFormer, GFPGAN)
stable_diffusion-faceswaplab_postprocessing_restore_face_model: "CodeFormer"

## Visibility of the restored faces (0.0 - 1.0)
stable_diffusion-faceswaplab_postprocessing_restore_face_visibility: 1

## Weight of the CodeFormer model (0.0 - 1.0)
stable_diffusion-faceswaplab_postprocessing_restore_face_codeformer_weight: 1

## Sets if color corrections should be applied
stable_diffusion-faceswaplab_color_corrections_enabled: false

## Sets the erosion factor for the mask
stable_diffusion-faceswaplab_mask_erosion_factor: 1

## Use improved segmented mask (use pastenetto mask only the face )
## Note: you should enable upscaling if you enable this option
stable_diffusion-faceswaplab_mask_improved_mask_enabled: false

## Sharpen the face
stable_diffusion-faceswaplab_sharpen_face: false

## Sets if faces should be blended in generated images
stable_diffusion-faceswaplab_blend_faces: true

#---------#
# ReActor #
#---------#

## Apply face swapping using ReActor.
## Requires the sd-webui-reactor extension to be installed.
## Repository: https://github.com/Gourieff/sd-webui-reactor

## Sets if faces should be swapped in generated images.
stable_diffusion-reactor_enabled: true

## Sets the source image with the face to use for face swapping.
## It's possible to set it in 3 ways:
##   1. Local file: "file:///./example.jpg"
##   2. URL: "https://some-site.com/example.png"
##   3. (recommended) ReActor face model: "checkpoint://example"
##      You can see the list of available checkpoints in the "models/reactor/faces" directory inside your Stable Diffusion WebUI directory.
stable_diffusion-reactor_source_face: "file:///{STABLE_DIFFUSION_EXTENSION_DIRECTORY}/assets/example_face.jpg"

## Sets the gender for the face in the source image (supported values: none, male, female)
## In other words, will only use the face with this gender as source face
stable_diffusion-reactor_source_gender: "none"

## Sets which gender to target in the generated image for swapping (supported values: none, male, female)
## In other words, will only swap a face of this gender
stable_diffusion-reactor_target_gender: "none"

## Use the nth face in the source face image as reference face
## Note: the first face is 0, the second face is 1, etc.
##
## Example:
## If you have 3 faces in the source image and set this to 1, it will use the second face from left to right and top to bottom.
stable_diffusion-reactor_source_face_index: 0

## Use the nth face in the generated image as the face to swap out
## See source_face_index for more info
stable_diffusion-reactor_target_face_index: 0

## Sets if the face should be enhanced (or "restored") after swapping
stable_diffusion-reactor_restore_face_enabled: false

## Model to use for restoring the face (CodeFormer, GFPGAN)
stable_diffusion-reactor_restore_face_model: "CodeFormer"

## Visibility of the restored face (0.0 - 1.0)
stable_diffusion-reactor_restore_face_visibility: 1

## Weight of the CodeFormer model (0.0 - 1.0)
stable_diffusion-reactor_restore_face_codeformer_weight: 1

## Upscale face first before enhancing it; otherwise restores face first then upscales it instead
stable_diffusion-reactor_restore_face_upscale_first: false

## Sets if the face should be upscaled.
stable_diffusion-reactor_upscaling_enabled: false

## Sets the upscaler to use for upscaling faces.
## Some examples are: Latent, LDSR, RealESRGAN 4x+, Lanczos, Nearest, etc.
stable_diffusion-reactor_upscaling_upscaler: "RealESRGAN 4x+"

## Amount to upscale the face by (1 = 100%, 2 = 200%, etc.).
stable_diffusion-reactor_upscaling_scale: 2

## Visibility of the upscaled face (0.0 - 1.0)
stable_diffusion-reactor_upscaling_visibility: 1

## Sets if face mask correction should be enabled to fix pixelation around face contours
stable_diffusion-reactor_mask_face: false

## Model to use for swapping faces
stable_diffusion-reactor_model: "inswapper_128.onnx"

## Device to use for swapping faces (CPU, CUDA).
## CUDA recommended for faster inference if you have an NVIDIA GPU.
## Note: CUDA requires installation of the onnxruntime-gpu package instead of onnxruntime in stable-diffusion-webui
stable_diffusion-reactor_device: "CPU"

#---------#
# FaceID  #
#---------#

## Apply face swapping using FaceID feature of SD.Next (a fork of AUTOMATIC1111).
## See: https://github.com/vladmandic/automatic for SD.Next repository.
##
## Works much better than ReActor or FaceSwapLab as
##   the face not actually swapped but instead directly
##   generated like the source face while the image is
##   still being generated.
##
## Works with stylized images too, e.g. 3D renders, drawings, cartoon, paintings etc.
##
## WARNING: DOES NOT WORK WITH VANILLA AUTOMATIC1111. YOU _MUST_ USE SD.NEXT INSTEAD.
##
## Requires "insightface", "ip_adapter" and "onnxruntime-gpu" PIP packages to be installed in SD.Next.

## Sets if faces should be swapped in generated images.
stable_diffusion-faceid_enabled: false

## Sets the source image with the face to use for face swapping.
## It's possible to set it in 2 difference ways:
##   1. Local file: "file:///./example.jpg"
##   2. URL: "https://some-site.com/example.png"
stable_diffusion-faceid_source_face: "file:///{STABLE_DIFFUSION_EXTENSION_DIRECTORY}/assets/example_face.jpg"

## FaceID mode
stable_diffusion-faceid_mode: ["FaceID", "FaceSwap"]

## Model to use for FaceID
## Available options:
## - FaceID Base
## - FaceID Plus
## - FaceID Plus v2
## - FaceID XL
stable_diffusion-faceid_model: "FaceID Plus v2"

## Use recommended sampler for FaceID
stable_diffusion-faceid_override_sampler: true

## Cache FaceID model for faster generation
stable_diffusion-faceid_cache_model: false

## FaceID strength (0.0 - 2.0)
stable_diffusion-faceid_strength: 1.0

## FaceID structure (0.0 - 1.0)
stable_diffusion-faceid_structure: 1.0

## FaceID rank (4 - 256)
stable_diffusion-faceid_rank: 128

## FaceID token count (1 - 16)
stable_diffusion-faceid_tokens: 4

#-------------#
# IP ADAPTER  #
#-------------#

## Adjust the IP Adapter integration feature of SD.Next (a fork of AUTOMATIC1111).
## See: https://github.com/vladmandic/automatic for SD.Next repository.
## See: https://ip-adapter.github.io/ for IP Adapter paper.
##
## Can be used for face swapping as well similar to the FaceID feature
## (by using the "Plus Face" or the "Full face" adapter).
##
## WARNING: DOES NOT WORK WITH VANILLA AUTOMATIC1111. YOU _MUST_ USE SD.NEXT INSTEAD.
## Requires "ip_adapter" and "onnxruntime-gpu" PIP packages to be installed in SD.Next.

## Sets if IP adapter should be enabled.
stable_diffusion-ipadapter_enabled: false

## Sets the source image to use for face swapping.
## It's possible to set it in 2 difference ways:
##   1. Local file: "file:///./example.jpg"
##   2. URL: "https://some-site.com/example.png"
stable_diffusion-ipadapter_reference_image: "file:///{STABLE_DIFFUSION_EXTENSION_DIRECTORY}/assets/example_face.jpg"

## The adapter to use.
## Possible values:
## - "Base"
## - "Light"
## - "Plus"
## - "Plus Face"
## - "Full face"
## - "Base SDXL"
stable_diffusion-ipadapter_adapter: "Base"

## Scale for the source face during image generation (0.0 - 1.0)
stable_diffusion-ipadapter_scale: 0.5
