# --------------------------------------------------------------------------------------------#
#                                  STABLE DIFFUSION EXTENSION                                 #
# This file contains the documentation and debug settings for the Stable Diffusion extension. #
# --------------------------------------------------------------------------------------------#

dark_theme: true
show_controls: true
mode: chat
chat_style: cai-chat
character: Assistant
preset: Debug-deterministic
seed: 1337
stream: true

default_extensions:
  - gallery
  - stable_diffusion

#----------------------#
# API ENDPOINT DETAILS #
#----------------------#

## Sets the API endpoint to use for generating images.
## If you are using the default stable-diffusion-webui settings, you do not need to change this.
stable_diffusion-api_endpoint: "http://127.0.0.1:7860/sdapi/v1"

## Leave as-is if you did not set up any authentication for the API.
stable_diffusion-api_username: ""
stable_diffusion-api_password: ""

#-----------------------------#
# IMAGE GENERATION PARAMETERS #
#-----------------------------#

stable_diffusion-base_prompt: "high resolution, detailed, realistic, vivid"
stable_diffusion-base_negative_prompt: "disformed, disfigured, blurry, low resolution, unrealistic, pixelated, low quality, low res"
stable_diffusion-sampler_name: "DPM SDE"
stable_diffusion-sampling_steps: 7
stable_diffusion-denoising_strength: 0.7
stable_diffusion-width: 1024
stable_diffusion-height: 1024
stable_diffusion-cfg_scale: 2
stable_diffusion-clip_skip: 1
stable_diffusion-seed: -1

#------------------#
# USER PREFERENCES #
#------------------#

## Sets if debug mode (e.g. for additional logs) should be enabled
stable_diffusion-debug_mode_enabled: true

## Sets if generated images should be saved to the "outputs" folder inside the stable_diffusion extension directory.
stable_diffusion-save_images: true

## Defines how image generation should be triggered. Possible values:
##  - "continuous": Always generate images.
##  - "interactive": Generate images only if a message with a triggering text was sent.
##  - "manual": Generates images only if the image generation button was pressed. (WIP, not implemented yet)
stable_diffusion-trigger_mode: "interactive"

## Set's how the prompt for image generation should be generated. Possible values:
##  - "static": Uses the prompt option as-is ignoring any chat context.
##  - "generated_text": Uses the generated output as-is as prompt.
##  - "dynamic": Generates a dynamic prompt using the subject_regex, default_subject and description_prompt options.
## The result is combined with the base_prompt and base_negative_prompt options.
stable_diffusion-interactive_mode_prompt_generation_mode: "dynamic"

## Defines the regex pattern for the input message which triggers image generation in interactive mode.
stable_diffusion-interactive_mode_input_trigger_regex: >-
  .*(send|upload|add|show|attach|generate)\b.+?\b(image|pic(ture)?|photo|snap(shot)?|selfie|meme)(s?)

## Defines the regex pattern for the generated output message which triggers image generation in interactive mode.
stable_diffusion-interactive_mode_output_trigger_regex: >-
  .*[*([](sends|uploads|adds|shows|attaches|generates|here (is|are))\b.+?\b(image|pic(ture)?|photo|snap(shot)?|selfie|meme)(s?)

## Defines the regex pattern for extracting the subject of the message for dynamic prompt generation in interactive mode.
## Only used when prompt_generation_mode is set to "dynamic".
stable_diffusion-interactive_mode_subject_regex: >-
  .*\b(of)\b(.+?)(?:[.!?]|$)

## Sets the default subject to use instead if no subject was found in the input message using the subject_regex option.
## Only used when prompt_generation_mode is set to "dynamic".
stable_diffusion-interactive_mode_default_subject: "your appearance, your surroundings and what you are doing right now"

## The text to use for generating a stable diffusion compatible description of the given subject. Replaces the original input message.
## Only used when prompt_generation_mode is set to "dynamic".
stable_diffusion-interactive_mode_description_prompt: >
  You are now a text generator for the Stable Diffusion AI image generator. You will generate a text prompt for it.

  Describe [subject] using comma-separated tags only. Do not use sentences.
  Include many tags such as tags for the environment, gender, clothes, age, location, light, daytime, angle, pose, etc.

  Very important: only write the comma-separated tags. Do not write anything else. Do not ask any questions. Do not talk.

## Set's how the base prompt for image generation should be generated. Possible values:
##  - "static": Uses the prompt option as-is ignoring any chat context.
##  - "generated_text": Uses the generated output as-is as prompt.
## The result is combined with the base_prompt and base_negative_prompt options.
stable_diffusion-continuous_mode_prompt_generation_mode: "generated_text"

## If enabled, will automatically unload the LLM model from VRAM and then load the SD model instead when generating images.
## After the image is generated, it will unload the SD model again and then reload the LLM model.
## Saves VRAM but will slow down generation speed. Only recommended if you have a low amount of VRAM or use very large models.
stable_diffusion-dynamic_vram_reallocation_enabled: false

## Do not stream messages if generating images at the same time. Improves generation speed.
stable_diffusion-dont_stream_when_generating_images: true

## Defines regex based rules that triggers the given actions.
## regex: The regex pattern that triggers the action (optional)
## negative_regex: Do not trigger the action if the text matches this regex (optional)
## match: A list of where to match the regex. Available options:
## - "input": match on input text.
## - "input_sentence": match on any sentence in input text.
#  - "output": match on generated output text.
#  - "output_sentence": match on any sentence in generated output text.
#  - "character_name": match on current character name (only if using gallery extension).
## actions: A list of actions to perform if the regex matches.
## - name: The name of the action to perform.
##   Available options:
##   - "prompt_append": appends the given text in "args" to the image generation prompt if an image is to be generated.
##   - "negative_prompt_append": appends the given text in "args" to the image generation negative prompt if an image is to be generated.
##   - "skip_generation": force skips any image generation.
##   - "faceswaplab_enable": force enables face swap with FaceSwapLab.
##   - "faceswaplab_disable": force disables face swap with FaceSwapLab.
##   - "faceswaplab_set_source_face": sets source face for FaceSwapLab (requires "args" to be set to a valid source face).
##   - "reactor_enable": force enables face swap with ReActor.
##   - "reactor_disable": force disables face swap with ReActor.
##   - "reactor_set_source_face": sets source face for ReActor (requires "args" to be set to a valid source face).
## - args: The arguments to pass to the action (optional).
stable_diffusion-generation_rules:
  # Add details to the prompt if the input text or output text contains the word "detailed".
  - regex: .*\b(detailed)\b
    match: ["input", "output"]
    actions:
      - name: "prompt_append"
        args: "(high resolution, detailed, realistic, vivid: 1.2), hdr, 8k, <lora:add_details:1>"

  # Append a prompt and negative prompt describing the characters look if the character's name equals "Assistant".
  - regex: ^Assistant$
    match: ["character_name"]
    actions:
      - name: "prompt_append"
        args: "small cute robot, monochrome, droid, 3d render, white reflective plastic body, simple, 3DMM, <lora:3DMM_V12:1>"
      - name: "negative_prompt_append"
        args: "humanoid, human, person, animal, anthropomorphic"

  # Enable face swap via FaceSwapLab (see below for documentation) if the character's name equals "Example".
  - regex: ^Example$
    match: ["character_name"]
    actions:
      - name: "faceswaplab_enable"
      - name: "faceswaplab_set_source_face"
        args: "file:///./extensions/stable_diffusion/assets/example_face.jpg"

#-----------------#
# POST PROCESSING #
#-----------------#

## Sets if generated images should be upscaled.
stable_diffusion-upscaling_enabled: false

## Sets the upscaler to use for upscaling generated images.
## Some examples are: Latent, LDSR, RealESRGAN 4x+, Lanczos, Nearest, etc.
stable_diffusion-upscaling_upscaler: "RealESRGAN 4x+"

## Amount to upscale by (1 = 100%, 2 = 200%, etc.).
stable_diffusion-upscaling_scale: 2

## Sets if faces should be enhanced (or "restored") in generated images.
stable_diffusion-enhance_faces_enabled: false

#-------------#
# FACESWAPLAB #
#-------------#

## Apply face swapping using FaceSwapLab.
## Requires the sd-webui-faceswaplab extension to be installed.
## Repository: https://github.com/glucauze/sd-webui-faceswaplab

## Sets if faces should be swapped in generated images.
stable_diffusion-faceswaplab_enabled: false

## Sets the source image with the face to use for face swapping.
## It's possible to set it in 3 ways:
##   1. Local file: "file:///./example.jpg"
##   2. URL: "https://some-site.com/example.png"
##   3. (recommended) FaceSwapLab face checkpoint: "checkpoint://example"
##      You can see the list of available checkpoints in the "models/faceswaplab/faces" directory inside your Stable Diffusion WebUI directory.
##      See https://github.com/glucauze/sd-webui-faceswaplab#build-and-use-checkpoints- for more on how to create face checkpoints.
stable_diffusion-faceswaplab_source_face: "file:///./extensions/stable_diffusion/assets/example_face.jpg"

## Only swap faces if same gender.
stable_diffusion-faceswaplab_same_gender_only: true

## If enabled, order source faces by size.
## Otherwise, order source faces from left to right.
stable_diffusion-faceswaplab_sort_by_size: true

## Use the nth face in the source face image as reference face
## Note: the first face is 0, the second face is 1, etc.
##
## Example:
## If you have 3 faces in the source image and set this to 1, it will use the second face from left to right if sort_by_size is set to false.
## If sort_by_size is true, it will use the second largest face instead.
stable_diffusion-faceswaplab_source_face_index: 0

## Use the nth face in the generated image as the face to swap out
## See source_face_index for more info
stable_diffusion-faceswaplab_target_face_index: 0

## Sets if the face should be upscaled
stable_diffusion-faceswaplab_upscaling_enabled: false

## Sets the upscaler to use for upscaling faces
## Some examples are: Latent, LDSR, RealESRGAN 4x+, Lanczos, Nearest, etc.
stable_diffusion-faceswaplab_upscaling_upscaler: "RealESRGAN 4x+"

## Amount to upscale the face by (1 = 100%, 2 = 200%, etc.)
stable_diffusion-faceswaplab_upscaling_scale: 2

## Visibility of the upscaled face (0.0 - 1.0)
stable_diffusion-faceswaplab_upscaling_visibility: 1

## Sets if the final result should be upscaled
stable_diffusion-faceswaplab_postprocessing_upscaling_enabled: false

## Sets the upscaler to use for upscaling final result image after swapping
## Some examples are: Latent, LDSR, RealESRGAN 4x+, Lanczos, Nearest, etc.
stable_diffusion-faceswaplab_postprocessing_upscaling_upscaler: "RealESRGAN 4x+"

## Amount to upscale the final result by (1 = 100%, 2 = 200%, etc.)
stable_diffusion-faceswaplab_postprocessing_upscaling_scale: 2

## Visibility of the final result upscale (0.0 - 1.0)
stable_diffusion-faceswaplab_postprocessing_upscaling_visibility: 1

## Sets if the face should be enhanced (or "restored") during swapping
stable_diffusion-faceswaplab_enhance_face_enabled: false

## Model to use for enhancing the face (CodeFormer, GFPGAN)
stable_diffusion-faceswaplab_enhance_face_model: "CodeFormer"

## Visibility of the enhanced face (0.0 - 1.0)
stable_diffusion-faceswaplab_enhance_face_visibility: 1

## Weight of the CodeFormer model (0.0 - 1.0)
stable_diffusion-faceswaplab_enhance_face_codeformer_weight: 1

## Sets if the faces should be enhanced (or "restored") in the final result image after swapping
stable_diffusion-faceswaplab_postprocessing_enhance_face_enabled: false

## Model to use for restoring the faces (CodeFormer, GFPGAN)
stable_diffusion-faceswaplab_postprocessing_enhance_face_model: "CodeFormer"

## Visibility of the enhanced faces (0.0 - 1.0)
stable_diffusion-faceswaplab_postprocessing_enhance_face_visibility: 1

## Weight of the CodeFormer model (0.0 - 1.0)
stable_diffusion-faceswaplab_postprocessing_enhance_face_codeformer_weight: 1

## Sets if color corrections should be applied
stable_diffusion-faceswaplab_color_corrections_enabled: false

## Sets the erosion factor for the mask
stable_diffusion-faceswaplab_mask_erosion_factor: 1

## Use improved segmented mask (use pastenetto mask only the face )
## Note: you should enable upscaling if you enable this option
stable_diffusion-faceswaplab_mask_improved_mask_enabled: false

## Sharpen the face
stable_diffusion-faceswaplab_sharpen_face: false

## Sets if faces should be blended in generated images
stable_diffusion-faceswaplab_blend_faces: true

#---------#
# ReActor #
#---------#

## Apply face swapping using ReActor.
## Requires the sd-webui-reactor extension to be installed.
## Repository: https://github.com/Gourieff/sd-webui-reactor

## Sets if faces should be swapped in generated images.
stable_diffusion-reactor_enabled: true

## Sets the source image with the face to use for face swapping.
## It's possible to set it in 3 ways:
##   1. Local file: "file:///./example.jpg"
##   2. URL: "https://some-site.com/example.png"
##   3. (recommended) ReActor face model: "checkpoint://example"
##      You can see the list of available checkpoints in the "models/reactor/faces" directory inside your Stable Diffusion WebUI directory.
stable_diffusion-reactor_source_face: "file:///./extensions/stable_diffusion/assets/example_face.jpg"

## Sets the gender for the face in the source image (supported values: none, male, female)
## In other words, will only use the face with this gender as source face
stable_diffusion-reactor_source_gender: "none"

## Sets which gender to target in the generated image for swapping (supported values: none, male, female)
## In other words, will only swap a face of this gender
stable_diffusion-reactor_target_gender: "none"

## Use the nth face in the source face image as reference face
## Note: the first face is 0, the second face is 1, etc.
##
## Example:
## If you have 3 faces in the source image and set this to 1, it will use the second face from left to right and top to bottom.
stable_diffusion-reactor_source_face_index: 0

## Use the nth face in the generated image as the face to swap out
## See source_face_index for more info
stable_diffusion-reactor_target_face_index: 0

## Sets if the face should be enhanced (or "restored") after swapping
stable_diffusion-reactor_enhance_face_enabled: false

## Model to use for restoring the face (CodeFormer, GFPGAN)
stable_diffusion-reactor_enhance_face_model: "CodeFormer"

## Visibility of the enhanced face (0.0 - 1.0)
stable_diffusion-reactor_enhance_face_visibility: 1

## Weight of the CodeFormer model (0.0 - 1.0)
stable_diffusion-reactor_enhance_face_codeformer_weight: 1

## Upscale face first before enhancing it; otherwise enhances face first then upscales it instead
stable_diffusion-reactor_enhance_face_upscale_first: false

## Sets if the face should be upscaled.
stable_diffusion-reactor_upscaling_enabled: false

## Sets the upscaler to use for upscaling faces.
## Some examples are: Latent, LDSR, RealESRGAN 4x+, Lanczos, Nearest, etc.
stable_diffusion-reactor_upscaling_upscaler: "RealESRGAN 4x+"

## Amount to upscale the face by (1 = 100%, 2 = 200%, etc.).
stable_diffusion-reactor_upscaling_scale: 2

## Visibility of the upscaled face (0.0 - 1.0)
stable_diffusion-reactor_upscaling_visibility: 1

## Sets if face mask correction should be enabled to fix pixelation around face contours
stable_diffusion-reactor_mask_face: false

## Model to use for swapping faces
stable_diffusion-reactor_model: "inswapper_128.onnx"

## Device to use for swapping faces (CPU, CUDA).
## CUDA recommended for faster inference if you have an NVIDIA GPU.
## Note: CUDA requires installation of the onnxruntime-gpu package instead of onnxruntime in stable-diffusion-webui
stable_diffusion-reactor_device: "CPU"
